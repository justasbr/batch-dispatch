import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

__weights_dict = dict()

def load_weights(weight_file):
    if weight_file == None:
        return

    try:
        weights_dict = np.load(weight_file).item()
    except:
        weights_dict = np.load(weight_file, encoding='bytes').item()

    return weights_dict

def t_relu(layer):
    return F.relu(layer, inplace=True)


class KitModel(nn.Module):

    
    def __init__(self, weight_file):
        super(KitModel, self).__init__()
        global __weights_dict
        __weights_dict = load_weights(weight_file)

        self.conv2d_1 = self.__conv(2, name='conv2d_1', in_channels=3, out_channels=32, kernel_size=(3, 3), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_1 = self.__batch_normalization(2, 'batch_normalization_1', num_features = 32, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_2 = self.__conv(2, name='conv2d_2', in_channels=32, out_channels=32, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_2 = self.__batch_normalization(2, 'batch_normalization_2', num_features = 32, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_3 = self.__conv(2, name='conv2d_3', in_channels=32, out_channels=64, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_3 = self.__batch_normalization(2, 'batch_normalization_3', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_4 = self.__conv(2, name='conv2d_4', in_channels=64, out_channels=80, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_4 = self.__batch_normalization(2, 'batch_normalization_4', num_features = 80, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_5 = self.__conv(2, name='conv2d_5', in_channels=80, out_channels=192, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_5 = self.__batch_normalization(2, 'batch_normalization_5', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_9 = self.__conv(2, name='conv2d_9', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_7 = self.__conv(2, name='conv2d_7', in_channels=192, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_6 = self.__conv(2, name='conv2d_6', in_channels=192, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_9 = self.__batch_normalization(2, 'batch_normalization_9', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_7 = self.__batch_normalization(2, 'batch_normalization_7', num_features = 48, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_12 = self.__conv(2, name='conv2d_12', in_channels=192, out_channels=32, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_6 = self.__batch_normalization(2, 'batch_normalization_6', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_12 = self.__batch_normalization(2, 'batch_normalization_12', num_features = 32, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_10 = self.__conv(2, name='conv2d_10', in_channels=64, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_8 = self.__conv(2, name='conv2d_8', in_channels=48, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_10 = self.__batch_normalization(2, 'batch_normalization_10', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_8 = self.__batch_normalization(2, 'batch_normalization_8', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_11 = self.__conv(2, name='conv2d_11', in_channels=96, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_11 = self.__batch_normalization(2, 'batch_normalization_11', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_16 = self.__conv(2, name='conv2d_16', in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_14 = self.__conv(2, name='conv2d_14', in_channels=256, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_13 = self.__conv(2, name='conv2d_13', in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_16 = self.__batch_normalization(2, 'batch_normalization_16', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_14 = self.__batch_normalization(2, 'batch_normalization_14', num_features = 48, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_19 = self.__conv(2, name='conv2d_19', in_channels=256, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_13 = self.__batch_normalization(2, 'batch_normalization_13', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_19 = self.__batch_normalization(2, 'batch_normalization_19', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_17 = self.__conv(2, name='conv2d_17', in_channels=64, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_15 = self.__conv(2, name='conv2d_15', in_channels=48, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_17 = self.__batch_normalization(2, 'batch_normalization_17', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_15 = self.__batch_normalization(2, 'batch_normalization_15', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_18 = self.__conv(2, name='conv2d_18', in_channels=96, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_18 = self.__batch_normalization(2, 'batch_normalization_18', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_23 = self.__conv(2, name='conv2d_23', in_channels=288, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_21 = self.__conv(2, name='conv2d_21', in_channels=288, out_channels=48, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_20 = self.__conv(2, name='conv2d_20', in_channels=288, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_23 = self.__batch_normalization(2, 'batch_normalization_23', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_21 = self.__batch_normalization(2, 'batch_normalization_21', num_features = 48, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_26 = self.__conv(2, name='conv2d_26', in_channels=288, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_20 = self.__batch_normalization(2, 'batch_normalization_20', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_26 = self.__batch_normalization(2, 'batch_normalization_26', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_24 = self.__conv(2, name='conv2d_24', in_channels=64, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_22 = self.__conv(2, name='conv2d_22', in_channels=48, out_channels=64, kernel_size=(5, 5), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_24 = self.__batch_normalization(2, 'batch_normalization_24', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_22 = self.__batch_normalization(2, 'batch_normalization_22', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_25 = self.__conv(2, name='conv2d_25', in_channels=96, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_25 = self.__batch_normalization(2, 'batch_normalization_25', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_28 = self.__conv(2, name='conv2d_28', in_channels=288, out_channels=64, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_27 = self.__conv(2, name='conv2d_27', in_channels=288, out_channels=384, kernel_size=(3, 3), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_28 = self.__batch_normalization(2, 'batch_normalization_28', num_features = 64, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_27 = self.__batch_normalization(2, 'batch_normalization_27', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_29 = self.__conv(2, name='conv2d_29', in_channels=64, out_channels=96, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_29 = self.__batch_normalization(2, 'batch_normalization_29', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_30 = self.__conv(2, name='conv2d_30', in_channels=96, out_channels=96, kernel_size=(3, 3), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_30 = self.__batch_normalization(2, 'batch_normalization_30', num_features = 96, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_35 = self.__conv(2, name='conv2d_35', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_32 = self.__conv(2, name='conv2d_32', in_channels=768, out_channels=128, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_31 = self.__conv(2, name='conv2d_31', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_35 = self.__batch_normalization(2, 'batch_normalization_35', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_32 = self.__batch_normalization(2, 'batch_normalization_32', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_40 = self.__conv(2, name='conv2d_40', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_31 = self.__batch_normalization(2, 'batch_normalization_31', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_40 = self.__batch_normalization(2, 'batch_normalization_40', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_36 = self.__conv(2, name='conv2d_36', in_channels=128, out_channels=128, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_33 = self.__conv(2, name='conv2d_33', in_channels=128, out_channels=128, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_36 = self.__batch_normalization(2, 'batch_normalization_36', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_33 = self.__batch_normalization(2, 'batch_normalization_33', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_37 = self.__conv(2, name='conv2d_37', in_channels=128, out_channels=128, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.conv2d_34 = self.__conv(2, name='conv2d_34', in_channels=128, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_37 = self.__batch_normalization(2, 'batch_normalization_37', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_34 = self.__batch_normalization(2, 'batch_normalization_34', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_38 = self.__conv(2, name='conv2d_38', in_channels=128, out_channels=128, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_38 = self.__batch_normalization(2, 'batch_normalization_38', num_features = 128, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_39 = self.__conv(2, name='conv2d_39', in_channels=128, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_39 = self.__batch_normalization(2, 'batch_normalization_39', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_45 = self.__conv(2, name='conv2d_45', in_channels=768, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_42 = self.__conv(2, name='conv2d_42', in_channels=768, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_41 = self.__conv(2, name='conv2d_41', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_45 = self.__batch_normalization(2, 'batch_normalization_45', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_42 = self.__batch_normalization(2, 'batch_normalization_42', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_50 = self.__conv(2, name='conv2d_50', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_41 = self.__batch_normalization(2, 'batch_normalization_41', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_50 = self.__batch_normalization(2, 'batch_normalization_50', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_46 = self.__conv(2, name='conv2d_46', in_channels=160, out_channels=160, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_43 = self.__conv(2, name='conv2d_43', in_channels=160, out_channels=160, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_46 = self.__batch_normalization(2, 'batch_normalization_46', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_43 = self.__batch_normalization(2, 'batch_normalization_43', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_47 = self.__conv(2, name='conv2d_47', in_channels=160, out_channels=160, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.conv2d_44 = self.__conv(2, name='conv2d_44', in_channels=160, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_47 = self.__batch_normalization(2, 'batch_normalization_47', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_44 = self.__batch_normalization(2, 'batch_normalization_44', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_48 = self.__conv(2, name='conv2d_48', in_channels=160, out_channels=160, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_48 = self.__batch_normalization(2, 'batch_normalization_48', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_49 = self.__conv(2, name='conv2d_49', in_channels=160, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_49 = self.__batch_normalization(2, 'batch_normalization_49', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_55 = self.__conv(2, name='conv2d_55', in_channels=768, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_52 = self.__conv(2, name='conv2d_52', in_channels=768, out_channels=160, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_51 = self.__conv(2, name='conv2d_51', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_55 = self.__batch_normalization(2, 'batch_normalization_55', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_52 = self.__batch_normalization(2, 'batch_normalization_52', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_60 = self.__conv(2, name='conv2d_60', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_51 = self.__batch_normalization(2, 'batch_normalization_51', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_60 = self.__batch_normalization(2, 'batch_normalization_60', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_56 = self.__conv(2, name='conv2d_56', in_channels=160, out_channels=160, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_53 = self.__conv(2, name='conv2d_53', in_channels=160, out_channels=160, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_56 = self.__batch_normalization(2, 'batch_normalization_56', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_53 = self.__batch_normalization(2, 'batch_normalization_53', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_57 = self.__conv(2, name='conv2d_57', in_channels=160, out_channels=160, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.conv2d_54 = self.__conv(2, name='conv2d_54', in_channels=160, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_57 = self.__batch_normalization(2, 'batch_normalization_57', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_54 = self.__batch_normalization(2, 'batch_normalization_54', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_58 = self.__conv(2, name='conv2d_58', in_channels=160, out_channels=160, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_58 = self.__batch_normalization(2, 'batch_normalization_58', num_features = 160, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_59 = self.__conv(2, name='conv2d_59', in_channels=160, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_59 = self.__batch_normalization(2, 'batch_normalization_59', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_65 = self.__conv(2, name='conv2d_65', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_62 = self.__conv(2, name='conv2d_62', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_61 = self.__conv(2, name='conv2d_61', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_65 = self.__batch_normalization(2, 'batch_normalization_65', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_62 = self.__batch_normalization(2, 'batch_normalization_62', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_70 = self.__conv(2, name='conv2d_70', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_61 = self.__batch_normalization(2, 'batch_normalization_61', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_70 = self.__batch_normalization(2, 'batch_normalization_70', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_66 = self.__conv(2, name='conv2d_66', in_channels=192, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_63 = self.__conv(2, name='conv2d_63', in_channels=192, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_66 = self.__batch_normalization(2, 'batch_normalization_66', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_63 = self.__batch_normalization(2, 'batch_normalization_63', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_67 = self.__conv(2, name='conv2d_67', in_channels=192, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.conv2d_64 = self.__conv(2, name='conv2d_64', in_channels=192, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_67 = self.__batch_normalization(2, 'batch_normalization_67', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_64 = self.__batch_normalization(2, 'batch_normalization_64', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_68 = self.__conv(2, name='conv2d_68', in_channels=192, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_68 = self.__batch_normalization(2, 'batch_normalization_68', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_69 = self.__conv(2, name='conv2d_69', in_channels=192, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_69 = self.__batch_normalization(2, 'batch_normalization_69', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_73 = self.__conv(2, name='conv2d_73', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_71 = self.__conv(2, name='conv2d_71', in_channels=768, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_73 = self.__batch_normalization(2, 'batch_normalization_73', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_71 = self.__batch_normalization(2, 'batch_normalization_71', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_74 = self.__conv(2, name='conv2d_74', in_channels=192, out_channels=192, kernel_size=(1, 7), stride=(1, 1), groups=1, bias=False)
        self.conv2d_72 = self.__conv(2, name='conv2d_72', in_channels=192, out_channels=320, kernel_size=(3, 3), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_74 = self.__batch_normalization(2, 'batch_normalization_74', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_72 = self.__batch_normalization(2, 'batch_normalization_72', num_features = 320, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_75 = self.__conv(2, name='conv2d_75', in_channels=192, out_channels=192, kernel_size=(7, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_75 = self.__batch_normalization(2, 'batch_normalization_75', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_76 = self.__conv(2, name='conv2d_76', in_channels=192, out_channels=192, kernel_size=(3, 3), stride=(2, 2), groups=1, bias=False)
        self.batch_normalization_76 = self.__batch_normalization(2, 'batch_normalization_76', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_81 = self.__conv(2, name='conv2d_81', in_channels=1280, out_channels=448, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_78 = self.__conv(2, name='conv2d_78', in_channels=1280, out_channels=384, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_77 = self.__conv(2, name='conv2d_77', in_channels=1280, out_channels=320, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_81 = self.__batch_normalization(2, 'batch_normalization_81', num_features = 448, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_78 = self.__batch_normalization(2, 'batch_normalization_78', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_85 = self.__conv(2, name='conv2d_85', in_channels=1280, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_77 = self.__batch_normalization(2, 'batch_normalization_77', num_features = 320, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_85 = self.__batch_normalization(2, 'batch_normalization_85', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_82 = self.__conv(2, name='conv2d_82', in_channels=448, out_channels=384, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_79 = self.__conv(2, name='conv2d_79', in_channels=384, out_channels=384, kernel_size=(1, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_80 = self.__conv(2, name='conv2d_80', in_channels=384, out_channels=384, kernel_size=(3, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_82 = self.__batch_normalization(2, 'batch_normalization_82', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_79 = self.__batch_normalization(2, 'batch_normalization_79', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_80 = self.__batch_normalization(2, 'batch_normalization_80', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_83 = self.__conv(2, name='conv2d_83', in_channels=384, out_channels=384, kernel_size=(1, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_84 = self.__conv(2, name='conv2d_84', in_channels=384, out_channels=384, kernel_size=(3, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_83 = self.__batch_normalization(2, 'batch_normalization_83', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_84 = self.__batch_normalization(2, 'batch_normalization_84', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_90 = self.__conv(2, name='conv2d_90', in_channels=2048, out_channels=448, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_87 = self.__conv(2, name='conv2d_87', in_channels=2048, out_channels=384, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.conv2d_86 = self.__conv(2, name='conv2d_86', in_channels=2048, out_channels=320, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_90 = self.__batch_normalization(2, 'batch_normalization_90', num_features = 448, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_87 = self.__batch_normalization(2, 'batch_normalization_87', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_94 = self.__conv(2, name='conv2d_94', in_channels=2048, out_channels=192, kernel_size=(1, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_86 = self.__batch_normalization(2, 'batch_normalization_86', num_features = 320, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_94 = self.__batch_normalization(2, 'batch_normalization_94', num_features = 192, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_91 = self.__conv(2, name='conv2d_91', in_channels=448, out_channels=384, kernel_size=(3, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_88 = self.__conv(2, name='conv2d_88', in_channels=384, out_channels=384, kernel_size=(1, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_89 = self.__conv(2, name='conv2d_89', in_channels=384, out_channels=384, kernel_size=(3, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_91 = self.__batch_normalization(2, 'batch_normalization_91', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_88 = self.__batch_normalization(2, 'batch_normalization_88', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_89 = self.__batch_normalization(2, 'batch_normalization_89', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.conv2d_92 = self.__conv(2, name='conv2d_92', in_channels=384, out_channels=384, kernel_size=(1, 3), stride=(1, 1), groups=1, bias=False)
        self.conv2d_93 = self.__conv(2, name='conv2d_93', in_channels=384, out_channels=384, kernel_size=(3, 1), stride=(1, 1), groups=1, bias=False)
        self.batch_normalization_92 = self.__batch_normalization(2, 'batch_normalization_92', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.batch_normalization_93 = self.__batch_normalization(2, 'batch_normalization_93', num_features = 384, eps = 0.0010000000474974513, momentum = 0.0)
        self.predictions = self.__dense(name = 'predictions', in_features = 2048, out_features = 1000, bias = True)

    def forward(self, x):
        conv2d_1        = self.conv2d_1(x)
        batch_normalization_1 = self.batch_normalization_1(conv2d_1)
        activation_1    = t_relu(batch_normalization_1)
        conv2d_2        = self.conv2d_2(activation_1)
        batch_normalization_2 = self.batch_normalization_2(conv2d_2)
        activation_2    = t_relu(batch_normalization_2)
        conv2d_3_pad    = F.pad(activation_2, (1, 1, 1, 1))
        conv2d_3        = self.conv2d_3(conv2d_3_pad)
        batch_normalization_3 = self.batch_normalization_3(conv2d_3)
        activation_3    = t_relu(batch_normalization_3)
        max_pooling2d_1 = F.max_pool2d(activation_3, kernel_size=(3, 3), stride=(2, 2))
        conv2d_4        = self.conv2d_4(max_pooling2d_1)
        batch_normalization_4 = self.batch_normalization_4(conv2d_4)
        activation_4    = t_relu(batch_normalization_4)
        conv2d_5        = self.conv2d_5(activation_4)
        batch_normalization_5 = self.batch_normalization_5(conv2d_5)
        activation_5    = t_relu(batch_normalization_5)
        max_pooling2d_2 = F.max_pool2d(activation_5, kernel_size=(3, 3), stride=(2, 2))
        conv2d_9        = self.conv2d_9(max_pooling2d_2)
        conv2d_7        = self.conv2d_7(max_pooling2d_2)
        average_pooling2d_1_pad = F.pad(max_pooling2d_2, (1, 1, 1, 1))
        average_pooling2d_1 = F.avg_pool2d(average_pooling2d_1_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_6        = self.conv2d_6(max_pooling2d_2)
        batch_normalization_9 = self.batch_normalization_9(conv2d_9)
        batch_normalization_7 = self.batch_normalization_7(conv2d_7)
        conv2d_12       = self.conv2d_12(average_pooling2d_1)
        batch_normalization_6 = self.batch_normalization_6(conv2d_6)
        activation_9    = t_relu(batch_normalization_9)
        activation_7    = t_relu(batch_normalization_7)
        batch_normalization_12 = self.batch_normalization_12(conv2d_12)
        activation_6    = t_relu(batch_normalization_6)
        conv2d_10_pad   = F.pad(activation_9, (1, 1, 1, 1))
        conv2d_10       = self.conv2d_10(conv2d_10_pad)
        conv2d_8_pad    = F.pad(activation_7, (2, 2, 2, 2))
        conv2d_8        = self.conv2d_8(conv2d_8_pad)
        activation_12   = t_relu(batch_normalization_12)
        batch_normalization_10 = self.batch_normalization_10(conv2d_10)
        batch_normalization_8 = self.batch_normalization_8(conv2d_8)
        activation_10   = t_relu(batch_normalization_10)
        activation_8    = t_relu(batch_normalization_8)
        conv2d_11_pad   = F.pad(activation_10, (1, 1, 1, 1))
        conv2d_11       = self.conv2d_11(conv2d_11_pad)
        batch_normalization_11 = self.batch_normalization_11(conv2d_11)
        activation_11   = t_relu(batch_normalization_11)
        mixed0          = torch.cat((activation_6, activation_8, activation_11, activation_12), 1)
        conv2d_16       = self.conv2d_16(mixed0)
        conv2d_14       = self.conv2d_14(mixed0)
        average_pooling2d_2_pad = F.pad(mixed0, (1, 1, 1, 1))
        average_pooling2d_2 = F.avg_pool2d(average_pooling2d_2_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_13       = self.conv2d_13(mixed0)
        batch_normalization_16 = self.batch_normalization_16(conv2d_16)
        batch_normalization_14 = self.batch_normalization_14(conv2d_14)
        conv2d_19       = self.conv2d_19(average_pooling2d_2)
        batch_normalization_13 = self.batch_normalization_13(conv2d_13)
        activation_16   = t_relu(batch_normalization_16)
        activation_14   = t_relu(batch_normalization_14)
        batch_normalization_19 = self.batch_normalization_19(conv2d_19)
        activation_13   = t_relu(batch_normalization_13)
        conv2d_17_pad   = F.pad(activation_16, (1, 1, 1, 1))
        conv2d_17       = self.conv2d_17(conv2d_17_pad)
        conv2d_15_pad   = F.pad(activation_14, (2, 2, 2, 2))
        conv2d_15       = self.conv2d_15(conv2d_15_pad)
        activation_19   = t_relu(batch_normalization_19)
        batch_normalization_17 = self.batch_normalization_17(conv2d_17)
        batch_normalization_15 = self.batch_normalization_15(conv2d_15)
        activation_17   = t_relu(batch_normalization_17)
        activation_15   = t_relu(batch_normalization_15)
        conv2d_18_pad   = F.pad(activation_17, (1, 1, 1, 1))
        conv2d_18       = self.conv2d_18(conv2d_18_pad)
        batch_normalization_18 = self.batch_normalization_18(conv2d_18)
        activation_18   = t_relu(batch_normalization_18)
        mixed1          = torch.cat((activation_13, activation_15, activation_18, activation_19), 1)
        conv2d_23       = self.conv2d_23(mixed1)
        conv2d_21       = self.conv2d_21(mixed1)
        average_pooling2d_3_pad = F.pad(mixed1, (1, 1, 1, 1))
        average_pooling2d_3 = F.avg_pool2d(average_pooling2d_3_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_20       = self.conv2d_20(mixed1)
        batch_normalization_23 = self.batch_normalization_23(conv2d_23)
        batch_normalization_21 = self.batch_normalization_21(conv2d_21)
        conv2d_26       = self.conv2d_26(average_pooling2d_3)
        batch_normalization_20 = self.batch_normalization_20(conv2d_20)
        activation_23   = t_relu(batch_normalization_23)
        activation_21   = t_relu(batch_normalization_21)
        batch_normalization_26 = self.batch_normalization_26(conv2d_26)
        activation_20   = t_relu(batch_normalization_20)
        conv2d_24_pad   = F.pad(activation_23, (1, 1, 1, 1))
        conv2d_24       = self.conv2d_24(conv2d_24_pad)
        conv2d_22_pad   = F.pad(activation_21, (2, 2, 2, 2))
        conv2d_22       = self.conv2d_22(conv2d_22_pad)
        activation_26   = t_relu(batch_normalization_26)
        batch_normalization_24 = self.batch_normalization_24(conv2d_24)
        batch_normalization_22 = self.batch_normalization_22(conv2d_22)
        activation_24   = t_relu(batch_normalization_24)
        activation_22   = t_relu(batch_normalization_22)
        conv2d_25_pad   = F.pad(activation_24, (1, 1, 1, 1))
        conv2d_25       = self.conv2d_25(conv2d_25_pad)
        batch_normalization_25 = self.batch_normalization_25(conv2d_25)
        activation_25   = t_relu(batch_normalization_25)
        mixed2          = torch.cat((activation_20, activation_22, activation_25, activation_26), 1)
        conv2d_28       = self.conv2d_28(mixed2)
        conv2d_27       = self.conv2d_27(mixed2)
        max_pooling2d_3 = F.max_pool2d(mixed2, kernel_size=(3, 3), stride=(2, 2))
        batch_normalization_28 = self.batch_normalization_28(conv2d_28)
        batch_normalization_27 = self.batch_normalization_27(conv2d_27)
        activation_28   = t_relu(batch_normalization_28)
        activation_27   = t_relu(batch_normalization_27)
        conv2d_29_pad   = F.pad(activation_28, (1, 1, 1, 1))
        conv2d_29       = self.conv2d_29(conv2d_29_pad)
        batch_normalization_29 = self.batch_normalization_29(conv2d_29)
        activation_29   = t_relu(batch_normalization_29)
        conv2d_30       = self.conv2d_30(activation_29)
        batch_normalization_30 = self.batch_normalization_30(conv2d_30)
        activation_30   = t_relu(batch_normalization_30)
        mixed3          = torch.cat((activation_27, activation_30, max_pooling2d_3), 1)
        conv2d_35       = self.conv2d_35(mixed3)
        conv2d_32       = self.conv2d_32(mixed3)
        average_pooling2d_4_pad = F.pad(mixed3, (1, 1, 1, 1))
        average_pooling2d_4 = F.avg_pool2d(average_pooling2d_4_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_31       = self.conv2d_31(mixed3)
        batch_normalization_35 = self.batch_normalization_35(conv2d_35)
        batch_normalization_32 = self.batch_normalization_32(conv2d_32)
        conv2d_40       = self.conv2d_40(average_pooling2d_4)
        batch_normalization_31 = self.batch_normalization_31(conv2d_31)
        activation_35   = t_relu(batch_normalization_35)
        activation_32   = t_relu(batch_normalization_32)
        batch_normalization_40 = self.batch_normalization_40(conv2d_40)
        activation_31   = t_relu(batch_normalization_31)
        conv2d_36_pad   = F.pad(activation_35, (0, 0, 3, 3))
        conv2d_36       = self.conv2d_36(conv2d_36_pad)
        conv2d_33_pad   = F.pad(activation_32, (3, 3, 0, 0))
        conv2d_33       = self.conv2d_33(conv2d_33_pad)
        activation_40   = t_relu(batch_normalization_40)
        batch_normalization_36 = self.batch_normalization_36(conv2d_36)
        batch_normalization_33 = self.batch_normalization_33(conv2d_33)
        activation_36   = t_relu(batch_normalization_36)
        activation_33   = t_relu(batch_normalization_33)
        conv2d_37_pad   = F.pad(activation_36, (3, 3, 0, 0))
        conv2d_37       = self.conv2d_37(conv2d_37_pad)
        conv2d_34_pad   = F.pad(activation_33, (0, 0, 3, 3))
        conv2d_34       = self.conv2d_34(conv2d_34_pad)
        batch_normalization_37 = self.batch_normalization_37(conv2d_37)
        batch_normalization_34 = self.batch_normalization_34(conv2d_34)
        activation_37   = t_relu(batch_normalization_37)
        activation_34   = t_relu(batch_normalization_34)
        conv2d_38_pad   = F.pad(activation_37, (0, 0, 3, 3))
        conv2d_38       = self.conv2d_38(conv2d_38_pad)
        batch_normalization_38 = self.batch_normalization_38(conv2d_38)
        activation_38   = t_relu(batch_normalization_38)
        conv2d_39_pad   = F.pad(activation_38, (3, 3, 0, 0))
        conv2d_39       = self.conv2d_39(conv2d_39_pad)
        batch_normalization_39 = self.batch_normalization_39(conv2d_39)
        activation_39   = t_relu(batch_normalization_39)
        mixed4          = torch.cat((activation_31, activation_34, activation_39, activation_40), 1)
        conv2d_45       = self.conv2d_45(mixed4)
        conv2d_42       = self.conv2d_42(mixed4)
        average_pooling2d_5_pad = F.pad(mixed4, (1, 1, 1, 1))
        average_pooling2d_5 = F.avg_pool2d(average_pooling2d_5_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_41       = self.conv2d_41(mixed4)
        batch_normalization_45 = self.batch_normalization_45(conv2d_45)
        batch_normalization_42 = self.batch_normalization_42(conv2d_42)
        conv2d_50       = self.conv2d_50(average_pooling2d_5)
        batch_normalization_41 = self.batch_normalization_41(conv2d_41)
        activation_45   = t_relu(batch_normalization_45)
        activation_42   = t_relu(batch_normalization_42)
        batch_normalization_50 = self.batch_normalization_50(conv2d_50)
        activation_41   = t_relu(batch_normalization_41)
        conv2d_46_pad   = F.pad(activation_45, (0, 0, 3, 3))
        conv2d_46       = self.conv2d_46(conv2d_46_pad)
        conv2d_43_pad   = F.pad(activation_42, (3, 3, 0, 0))
        conv2d_43       = self.conv2d_43(conv2d_43_pad)
        activation_50   = t_relu(batch_normalization_50)
        batch_normalization_46 = self.batch_normalization_46(conv2d_46)
        batch_normalization_43 = self.batch_normalization_43(conv2d_43)
        activation_46   = t_relu(batch_normalization_46)
        activation_43   = t_relu(batch_normalization_43)
        conv2d_47_pad   = F.pad(activation_46, (3, 3, 0, 0))
        conv2d_47       = self.conv2d_47(conv2d_47_pad)
        conv2d_44_pad   = F.pad(activation_43, (0, 0, 3, 3))
        conv2d_44       = self.conv2d_44(conv2d_44_pad)
        batch_normalization_47 = self.batch_normalization_47(conv2d_47)
        batch_normalization_44 = self.batch_normalization_44(conv2d_44)
        activation_47   = t_relu(batch_normalization_47)
        activation_44   = t_relu(batch_normalization_44)
        conv2d_48_pad   = F.pad(activation_47, (0, 0, 3, 3))
        conv2d_48       = self.conv2d_48(conv2d_48_pad)
        batch_normalization_48 = self.batch_normalization_48(conv2d_48)
        activation_48   = t_relu(batch_normalization_48)
        conv2d_49_pad   = F.pad(activation_48, (3, 3, 0, 0))
        conv2d_49       = self.conv2d_49(conv2d_49_pad)
        batch_normalization_49 = self.batch_normalization_49(conv2d_49)
        activation_49   = t_relu(batch_normalization_49)
        mixed5          = torch.cat((activation_41, activation_44, activation_49, activation_50), 1)
        conv2d_55       = self.conv2d_55(mixed5)
        conv2d_52       = self.conv2d_52(mixed5)
        average_pooling2d_6_pad = F.pad(mixed5, (1, 1, 1, 1))
        average_pooling2d_6 = F.avg_pool2d(average_pooling2d_6_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_51       = self.conv2d_51(mixed5)
        batch_normalization_55 = self.batch_normalization_55(conv2d_55)
        batch_normalization_52 = self.batch_normalization_52(conv2d_52)
        conv2d_60       = self.conv2d_60(average_pooling2d_6)
        batch_normalization_51 = self.batch_normalization_51(conv2d_51)
        activation_55   = t_relu(batch_normalization_55)
        activation_52   = t_relu(batch_normalization_52)
        batch_normalization_60 = self.batch_normalization_60(conv2d_60)
        activation_51   = t_relu(batch_normalization_51)
        conv2d_56_pad   = F.pad(activation_55, (0, 0, 3, 3))
        conv2d_56       = self.conv2d_56(conv2d_56_pad)
        conv2d_53_pad   = F.pad(activation_52, (3, 3, 0, 0))
        conv2d_53       = self.conv2d_53(conv2d_53_pad)
        activation_60   = t_relu(batch_normalization_60)
        batch_normalization_56 = self.batch_normalization_56(conv2d_56)
        batch_normalization_53 = self.batch_normalization_53(conv2d_53)
        activation_56   = t_relu(batch_normalization_56)
        activation_53   = t_relu(batch_normalization_53)
        conv2d_57_pad   = F.pad(activation_56, (3, 3, 0, 0))
        conv2d_57       = self.conv2d_57(conv2d_57_pad)
        conv2d_54_pad   = F.pad(activation_53, (0, 0, 3, 3))
        conv2d_54       = self.conv2d_54(conv2d_54_pad)
        batch_normalization_57 = self.batch_normalization_57(conv2d_57)
        batch_normalization_54 = self.batch_normalization_54(conv2d_54)
        activation_57   = t_relu(batch_normalization_57)
        activation_54   = t_relu(batch_normalization_54)
        conv2d_58_pad   = F.pad(activation_57, (0, 0, 3, 3))
        conv2d_58       = self.conv2d_58(conv2d_58_pad)
        batch_normalization_58 = self.batch_normalization_58(conv2d_58)
        activation_58   = t_relu(batch_normalization_58)
        conv2d_59_pad   = F.pad(activation_58, (3, 3, 0, 0))
        conv2d_59       = self.conv2d_59(conv2d_59_pad)
        batch_normalization_59 = self.batch_normalization_59(conv2d_59)
        activation_59   = t_relu(batch_normalization_59)
        mixed6          = torch.cat((activation_51, activation_54, activation_59, activation_60), 1)
        conv2d_65       = self.conv2d_65(mixed6)
        conv2d_62       = self.conv2d_62(mixed6)
        average_pooling2d_7_pad = F.pad(mixed6, (1, 1, 1, 1))
        average_pooling2d_7 = F.avg_pool2d(average_pooling2d_7_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_61       = self.conv2d_61(mixed6)
        batch_normalization_65 = self.batch_normalization_65(conv2d_65)
        batch_normalization_62 = self.batch_normalization_62(conv2d_62)
        conv2d_70       = self.conv2d_70(average_pooling2d_7)
        batch_normalization_61 = self.batch_normalization_61(conv2d_61)
        activation_65   = t_relu(batch_normalization_65)
        activation_62   = t_relu(batch_normalization_62)
        batch_normalization_70 = self.batch_normalization_70(conv2d_70)
        activation_61   = t_relu(batch_normalization_61)
        conv2d_66_pad   = F.pad(activation_65, (0, 0, 3, 3))
        conv2d_66       = self.conv2d_66(conv2d_66_pad)
        conv2d_63_pad   = F.pad(activation_62, (3, 3, 0, 0))
        conv2d_63       = self.conv2d_63(conv2d_63_pad)
        activation_70   = t_relu(batch_normalization_70)
        batch_normalization_66 = self.batch_normalization_66(conv2d_66)
        batch_normalization_63 = self.batch_normalization_63(conv2d_63)
        activation_66   = t_relu(batch_normalization_66)
        activation_63   = t_relu(batch_normalization_63)
        conv2d_67_pad   = F.pad(activation_66, (3, 3, 0, 0))
        conv2d_67       = self.conv2d_67(conv2d_67_pad)
        conv2d_64_pad   = F.pad(activation_63, (0, 0, 3, 3))
        conv2d_64       = self.conv2d_64(conv2d_64_pad)
        batch_normalization_67 = self.batch_normalization_67(conv2d_67)
        batch_normalization_64 = self.batch_normalization_64(conv2d_64)
        activation_67   = t_relu(batch_normalization_67)
        activation_64   = t_relu(batch_normalization_64)
        conv2d_68_pad   = F.pad(activation_67, (0, 0, 3, 3))
        conv2d_68       = self.conv2d_68(conv2d_68_pad)
        batch_normalization_68 = self.batch_normalization_68(conv2d_68)
        activation_68   = t_relu(batch_normalization_68)
        conv2d_69_pad   = F.pad(activation_68, (3, 3, 0, 0))
        conv2d_69       = self.conv2d_69(conv2d_69_pad)
        batch_normalization_69 = self.batch_normalization_69(conv2d_69)
        activation_69   = t_relu(batch_normalization_69)
        mixed7          = torch.cat((activation_61, activation_64, activation_69, activation_70), 1)
        conv2d_73       = self.conv2d_73(mixed7)
        conv2d_71       = self.conv2d_71(mixed7)
        max_pooling2d_4 = F.max_pool2d(mixed7, kernel_size=(3, 3), stride=(2, 2))
        batch_normalization_73 = self.batch_normalization_73(conv2d_73)
        batch_normalization_71 = self.batch_normalization_71(conv2d_71)
        activation_73   = t_relu(batch_normalization_73)
        activation_71   = t_relu(batch_normalization_71)
        conv2d_74_pad   = F.pad(activation_73, (3, 3, 0, 0))
        conv2d_74       = self.conv2d_74(conv2d_74_pad)
        conv2d_72       = self.conv2d_72(activation_71)
        batch_normalization_74 = self.batch_normalization_74(conv2d_74)
        batch_normalization_72 = self.batch_normalization_72(conv2d_72)
        activation_74   = t_relu(batch_normalization_74)
        activation_72   = t_relu(batch_normalization_72)
        conv2d_75_pad   = F.pad(activation_74, (0, 0, 3, 3))
        conv2d_75       = self.conv2d_75(conv2d_75_pad)
        batch_normalization_75 = self.batch_normalization_75(conv2d_75)
        activation_75   = t_relu(batch_normalization_75)
        conv2d_76       = self.conv2d_76(activation_75)
        batch_normalization_76 = self.batch_normalization_76(conv2d_76)
        activation_76   = t_relu(batch_normalization_76)
        mixed8          = torch.cat((activation_72, activation_76, max_pooling2d_4), 1)
        conv2d_81       = self.conv2d_81(mixed8)
        conv2d_78       = self.conv2d_78(mixed8)
        average_pooling2d_8_pad = F.pad(mixed8, (1, 1, 1, 1))
        average_pooling2d_8 = F.avg_pool2d(average_pooling2d_8_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_77       = self.conv2d_77(mixed8)
        batch_normalization_81 = self.batch_normalization_81(conv2d_81)
        batch_normalization_78 = self.batch_normalization_78(conv2d_78)
        conv2d_85       = self.conv2d_85(average_pooling2d_8)
        batch_normalization_77 = self.batch_normalization_77(conv2d_77)
        activation_81   = t_relu(batch_normalization_81)
        activation_78   = t_relu(batch_normalization_78)
        batch_normalization_85 = self.batch_normalization_85(conv2d_85)
        activation_77   = t_relu(batch_normalization_77)
        conv2d_82_pad   = F.pad(activation_81, (1, 1, 1, 1))
        conv2d_82       = self.conv2d_82(conv2d_82_pad)
        conv2d_79_pad   = F.pad(activation_78, (1, 1, 0, 0))
        conv2d_79       = self.conv2d_79(conv2d_79_pad)
        conv2d_80_pad   = F.pad(activation_78, (0, 0, 1, 1))
        conv2d_80       = self.conv2d_80(conv2d_80_pad)
        activation_85   = t_relu(batch_normalization_85)
        batch_normalization_82 = self.batch_normalization_82(conv2d_82)
        batch_normalization_79 = self.batch_normalization_79(conv2d_79)
        batch_normalization_80 = self.batch_normalization_80(conv2d_80)
        activation_82   = t_relu(batch_normalization_82)
        activation_79   = t_relu(batch_normalization_79)
        activation_80   = t_relu(batch_normalization_80)
        conv2d_83_pad   = F.pad(activation_82, (1, 1, 0, 0))
        conv2d_83       = self.conv2d_83(conv2d_83_pad)
        conv2d_84_pad   = F.pad(activation_82, (0, 0, 1, 1))
        conv2d_84       = self.conv2d_84(conv2d_84_pad)
        mixed9_0        = torch.cat((activation_79, activation_80), 1)
        batch_normalization_83 = self.batch_normalization_83(conv2d_83)
        batch_normalization_84 = self.batch_normalization_84(conv2d_84)
        activation_83   = t_relu(batch_normalization_83)
        activation_84   = t_relu(batch_normalization_84)
        concatenate_1   = torch.cat((activation_83, activation_84), 1)
        mixed9          = torch.cat((activation_77, mixed9_0, concatenate_1, activation_85), 1)
        conv2d_90       = self.conv2d_90(mixed9)
        conv2d_87       = self.conv2d_87(mixed9)
        average_pooling2d_9_pad = F.pad(mixed9, (1, 1, 1, 1))
        average_pooling2d_9 = F.avg_pool2d(average_pooling2d_9_pad, kernel_size=(3, 3), stride=(1, 1))
        conv2d_86       = self.conv2d_86(mixed9)
        batch_normalization_90 = self.batch_normalization_90(conv2d_90)
        batch_normalization_87 = self.batch_normalization_87(conv2d_87)
        conv2d_94       = self.conv2d_94(average_pooling2d_9)
        batch_normalization_86 = self.batch_normalization_86(conv2d_86)
        activation_90   = t_relu(batch_normalization_90)
        activation_87   = t_relu(batch_normalization_87)
        batch_normalization_94 = self.batch_normalization_94(conv2d_94)
        activation_86   = t_relu(batch_normalization_86)
        conv2d_91_pad   = F.pad(activation_90, (1, 1, 1, 1))
        conv2d_91       = self.conv2d_91(conv2d_91_pad)
        conv2d_88_pad   = F.pad(activation_87, (1, 1, 0, 0))
        conv2d_88       = self.conv2d_88(conv2d_88_pad)
        conv2d_89_pad   = F.pad(activation_87, (0, 0, 1, 1))
        conv2d_89       = self.conv2d_89(conv2d_89_pad)
        activation_94   = t_relu(batch_normalization_94)
        batch_normalization_91 = self.batch_normalization_91(conv2d_91)
        batch_normalization_88 = self.batch_normalization_88(conv2d_88)
        batch_normalization_89 = self.batch_normalization_89(conv2d_89)
        activation_91   = t_relu(batch_normalization_91)
        activation_88   = t_relu(batch_normalization_88)
        activation_89   = t_relu(batch_normalization_89)
        conv2d_92_pad   = F.pad(activation_91, (1, 1, 0, 0))
        conv2d_92       = self.conv2d_92(conv2d_92_pad)
        conv2d_93_pad   = F.pad(activation_91, (0, 0, 1, 1))
        conv2d_93       = self.conv2d_93(conv2d_93_pad)
        mixed9_1        = torch.cat((activation_88, activation_89), 1)
        batch_normalization_92 = self.batch_normalization_92(conv2d_92)
        batch_normalization_93 = self.batch_normalization_93(conv2d_93)
        activation_92   = t_relu(batch_normalization_92)
        activation_93   = t_relu(batch_normalization_93)
        concatenate_2   = torch.cat((activation_92, activation_93), 1)
        mixed10         = torch.cat((activation_86, mixed9_1, concatenate_2, activation_94), 1)
        avg_pool        = F.avg_pool2d(input = mixed10, kernel_size = mixed10.size()[2:])
        avg_pool_flatten = avg_pool.view(avg_pool.size(0), -1)
        predictions     = self.predictions(avg_pool_flatten)
        predictions_activation = F.softmax(predictions)
        return predictions_activation


    @staticmethod
    def __dense(name, **kwargs):
        layer = nn.Linear(**kwargs)
        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

    @staticmethod
    def __conv(dim, name, **kwargs):
        if   dim == 1:  layer = nn.Conv1d(**kwargs)
        elif dim == 2:  layer = nn.Conv2d(**kwargs)
        elif dim == 3:  layer = nn.Conv3d(**kwargs)
        else:           raise NotImplementedError()

        layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['weights']))
        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        return layer

    @staticmethod
    def __batch_normalization(dim, name, **kwargs):
        if   dim == 1:  layer = nn.BatchNorm1d(**kwargs)
        elif dim == 2:  layer = nn.BatchNorm2d(**kwargs)
        elif dim == 3:  layer = nn.BatchNorm3d(**kwargs)
        else:           raise NotImplementedError()

        if 'scale' in __weights_dict[name]:
            layer.state_dict()['weight'].copy_(torch.from_numpy(__weights_dict[name]['scale']))
        else:
            layer.weight.data.fill_(1)

        if 'bias' in __weights_dict[name]:
            layer.state_dict()['bias'].copy_(torch.from_numpy(__weights_dict[name]['bias']))
        else:
            layer.bias.data.fill_(0)

        layer.state_dict()['running_mean'].copy_(torch.from_numpy(__weights_dict[name]['mean']))
        layer.state_dict()['running_var'].copy_(torch.from_numpy(__weights_dict[name]['var']))
        return layer
